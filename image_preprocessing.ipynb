{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we preprocess the images, i.e normalization and also we augment the data (migh use later on);<br>\n",
    "They are saved in NormalizedData and AugmentedData directories respectfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import mlflow\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import torch.optim as optim\n",
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the dataset\n",
    "base_path = \"Data\"\n",
    "vegetable_images_path = os.path.join(base_path, \"VegetableImages\")\n",
    "holed_images_path = os.path.join(base_path, \"HoledImages\")\n",
    "output_normalized_path = \"NormalizedData\"\n",
    "output_augmented_path = \"AugmentedData\"\n",
    "\n",
    "# Transformations\n",
    "normalize_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert image to tensor with values in [0, 1]\n",
    "    # transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "augmentation_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Function to process images\n",
    "def preprocess_images(input_path, output_path, transform, process_type=\"normalization\"):\n",
    "    for root, _, files in os.walk(input_path):\n",
    "        for file in files:\n",
    "            if file.endswith(('.png', '.jpg', '.jpeg')):  # Add supported image formats\n",
    "                img_path = os.path.join(root, file)\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                processed_img = transform(img)\n",
    "                \n",
    "                # Convert tensor to numpy array for saving\n",
    "                np_img = processed_img.numpy().transpose(1, 2, 0)\n",
    "                \n",
    "                # Save image in the corresponding output folder\n",
    "                save_path = os.path.join(output_path, os.path.relpath(img_path, input_path))\n",
    "                os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "                Image.fromarray((np_img * 255).astype('uint8')).save(save_path)\n",
    "                print(f\"{process_type.capitalize()} processed: {save_path}\")\n",
    "\n",
    "# MLflow Integration\n",
    "mlflow.set_experiment(\"Image Inpainting Preprocessing\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Preprocessing with better normalization\") as run:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Log parameters for normalization and augmentation\n",
    "    mlflow.log_param(\"Normalization\", \"[-1, 1]\")\n",
    "    mlflow.log_param(\"Augmentation\", \"RandomHorizontalFlip, RandomRotation, ColorJitter\")\n",
    "    \n",
    "    # Normalize VegetableImages\n",
    "    print(\"Normalizing VegetableImages...\")\n",
    "    preprocess_images(vegetable_images_path, os.path.join(output_normalized_path, \"VegetableImages\"), normalize_transform, process_type=\"normalization\")\n",
    "    mlflow.log_artifacts(os.path.join(output_normalized_path, \"VegetableImages\"), artifact_path=\"NormalizedVegetableImages\")\n",
    "\n",
    "    # Normalize HoledImages\n",
    "    print(\"Normalizing HoledImages...\")\n",
    "    preprocess_images(holed_images_path, os.path.join(output_normalized_path, \"HoledImages\"), normalize_transform, process_type=\"normalization\")\n",
    "    mlflow.log_artifacts(os.path.join(output_normalized_path, \"HoledImages\"), artifact_path=\"NormalizedHoledImages\")\n",
    "    \n",
    "    # Augment VegetableImages\n",
    "    print(\"Augmenting VegetableImages...\")\n",
    "    preprocess_images(vegetable_images_path, os.path.join(output_augmented_path, \"VegetableImages\"), augmentation_transforms, process_type=\"augmentation\")\n",
    "    mlflow.log_artifacts(os.path.join(output_augmented_path, \"VegetableImages\"), artifact_path=\"AugmentedVegetableImages\")\n",
    "\n",
    "    # Augment HoledImages\n",
    "    print(\"Augmenting HoledImages...\")\n",
    "    preprocess_images(holed_images_path, os.path.join(output_augmented_path, \"HoledImages\"), augmentation_transforms, process_type=\"augmentation\")\n",
    "    mlflow.log_artifacts(os.path.join(output_augmented_path, \"HoledImages\"), artifact_path=\"AugmentedHoledImages\")\n",
    "    \n",
    "    # Log time taken for preprocessing\n",
    "    total_time = time.time() - start_time\n",
    "    mlflow.log_metric(\"Preprocessing_Time_(seconds)\", total_time)\n",
    "    print(f\"Preprocessing completed in {total_time:.2f} seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
